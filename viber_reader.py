import os
import time
import threading
import pytesseract
from PIL import Image
from settings import TESSERACT_PATH, OCR_LANGUAGES, CITY_DATABASE_PATH
from telegram_sender import send_to_telegram
from debug_logger import add_debug, update_stats
from rapidfuzz import fuzz

pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH

def delete_file_later(filepath, delay=60):
    def delayed():
        time.sleep(delay)
        try:
            os.remove(filepath)
        except:
            pass
    threading.Thread(target=delayed, daemon=True).start()

def load_city_database():
    cities = {}
    for root, dirs, files in os.walk(CITY_DATABASE_PATH):
        for file in files:
            if file.endswith(".txt"):
                with open(os.path.join(root, file), "r", encoding="utf-8") as f:
                    for line in f:
                        parts = line.strip().split("â€”")
                        if len(parts) >= 2:
                            name = parts[0].strip()
                            cities[name.lower()] = {
                                "original": name,
                                "ukrainian": parts[1].strip(),
                                "zip": parts[2].strip() if len(parts) > 2 else "",
                            }
    return cities

def extract_blocks(text):
    return [block.strip() for block in text.split("\n") if len(block.strip()) > 5]

def classify(text):
    text = text.lower()
    if any(word in text for word in ["Ğ¿Ğ°ÑĞ°Ğ¶Ğ¸Ñ€", "Ğ¿Ğ°Ñ", "Ğ»ÑĞ´Ğ¸Ğ½Ğ°", "Ğ¼Ñ–ÑÑ†Ğµ"]):
        return "ğŸ‘¤ ĞŸĞ°ÑĞ°Ğ¶Ğ¸Ñ€"
    elif any(word in text for word in ["Ğ¿Ğ¾ÑĞ¸Ğ»ĞºĞ°", "Ğ¿Ğ°ĞºÑƒĞ½Ğ¾Ğº", "ĞºĞ³", "Ğ´Ğ¾Ğº", "Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ°"]):
        return "ğŸ“¦ ĞŸĞ¾ÑĞ¸Ğ»ĞºĞ°"
    elif any(word in text for word in ["Ğ´Ğ¸Ñ‚", "Ğ½ĞµĞ¼Ğ¾Ğ²Ğ»Ñ", "Ğ¼Ğ°Ğ»ÑĞº"]):
        return "ğŸ‘¶ Ğ”Ğ¸Ñ‚Ğ¸Ğ½Ğ°"
    elif any(word in text for word in ["Ñ‚Ğ²Ğ°Ñ€Ğ¸Ğ½", "ĞºÑ–Ñ‚", "Ğ¿ĞµÑ", "ÑĞ¾Ğ±Ğ°ĞºĞ°"]):
        return "ğŸ¾ Ğ¢Ğ²Ğ°Ñ€Ğ¸Ğ½Ğ°"
    return "â“ ĞĞµĞ²Ñ–Ğ´Ğ¾Ğ¼Ğ¾"

def find_cities(text, db, threshold=80):
    found = []
    for word in text.split():
        word = word.strip(",.!?-_").lower()
        for city in db:
            score = fuzz.ratio(word, city)
            if score >= threshold:
                found.append((city, db[city]))
                add_debug(f"ğŸ¯ Ğ—Ğ±Ñ–Ğ³: {word} â‰ˆ {city} ({score}%)")
    return found

def generate_map_link(city_name):
    return f"https://www.google.com/maps/search/{city_name.replace(' ', '+')}"

def process_image(image_path):
    try:
        add_debug(f"ğŸ“· ĞĞ±Ñ€Ğ¾Ğ±ĞºĞ° Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ: {image_path}")
        image = Image.open(image_path)
        ocr_text = pytesseract.image_to_string(image, lang=OCR_LANGUAGES)
        add_debug('ğŸ“„ OCR TEXT:\n' + ocr_text)

        blocks = extract_blocks(ocr_text)
        db = load_city_database()

        for block in blocks:
            found = find_cities(block, db)
            if len(found) >= 2:
                city1, data1 = found[0]
                city2, data2 = found[1]
                category = classify(block)
                update_stats(data1["ukrainian"])
                update_stats(data2["ukrainian"])

                bolded = block
                for city in (city1, city2):
                    bolded = bolded.replace(city, f"<b>{city}</b>")

                msg = f"""<b>ğŸ” Ğ’Ğ¸ÑĞ²Ğ»ĞµĞ½Ğ¾ Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚</b>
ğŸ“„ <i>{bolded}</i>

ğŸ“ {data1["original"]} â€” {data1["ukrainian"]} â¡ {data2["original"]} â€” {data2["ukrainian"]}
ğŸ”– ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ñ: {category}
ğŸ· Ğ†Ğ½Ğ´ĞµĞºÑĞ¸: {data1["zip"]} â¡ {data2["zip"]}
ğŸŒ ĞœĞ°Ğ¿Ğ°: {generate_map_link(data1["original"])} â¡ {generate_map_link(data2["original"])}
"""

                asyncio.run(send_to_telegram(msg.strip(), image_path))
                add_debug(f"ğŸ“¨ ĞĞ°Ğ´Ñ–ÑĞ»Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ: {data1['ukrainian']} â¡ {data2['ukrainian']}")
                break
            else:
                add_debug("âš ï¸ ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ½ÑŒĞ¾ Ğ¼Ñ–ÑÑ‚ Ñƒ Ğ±Ğ»Ğ¾Ñ†Ñ–")

        delete_file_later(image_path)
    except Exception as e:
        add_debug(f"âŒ ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¾Ğ±Ñ€Ğ¾Ğ±Ñ†Ñ–: {e}")